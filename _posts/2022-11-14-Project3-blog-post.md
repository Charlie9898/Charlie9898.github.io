In this project, we established a set of predictive models for the Online News Popularity Data Set with automating mechanism. We want to predict the number of shares in social networks (popularity). The dataset we used in this project contains 39,644 observations with 61 variables. The entire dataset was divided into six sub-sets according to the value of `data_channel`. Two linear regression models and two ensemble models were fitted for each sub-dataset.  

The project and repo were initialized by my partner Kelley. I drafted the narratives for the Introduction, data subset, partial summarizations, boosted model, linear model 1, and comparison section. I finished the code for the data subset, partial summarizations, boosted model, linear model 1, and comparison section.  

Here are a few discussions:  
1. What would you do differently?  
Actually the process is pretty smooth. There is hardly any rework. Maybe next time I will test some predictor sets before selecting them as the final predictors for better performance.

2. What was the most difficult part for you?
The automating and rendering section is kind of hard to understand. I am not very sure about the mechanism of GitHub to render our .md file even after we finished the project. How should we set up the .md, and how does GitHub identify and render these contents?

3. What are your big take-aways from this project?
When developing a data analysis program, it can save much time to consider applying automating. The key idea should be generalizing the data format and code for performing the analysis. The narratives should also be reasonable for the generated batch of reports.

Rendered page: https://kebreeze.github.io/558Project3/
Repo: https://github.com/kebreeze/558Project3
